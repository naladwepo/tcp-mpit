"""
LLM Validator - —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å—É, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç—å
"""

import json
import re
from typing import List, Dict, Optional, Any, Tuple
from pathlib import Path


class LLMValidator:
    """
    LLM –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
    
    –§—É–Ω–∫—Ü–∏–∏:
    1. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å—É
    2. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
    3. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–æ–∏–º–æ—Å—Ç—å
    4. –ú–æ–∂–µ—Ç –∑–∞–ø—Ä–æ—Å–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç
    """
    
    def __init__(
        self, 
        model_path: str = "./Qwen/Qwen3-4B-Instruct-2507",
        use_llm: bool = True
    ):
        """
        Args:
            model_path: –ø—É—Ç—å –∫ LLM –º–æ–¥–µ–ª–∏
            use_llm: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ LLM (False = –ø—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏)
        """
        self.model_path = Path(model_path)
        self.model = None
        self.tokenizer = None
        self.use_llm = use_llm
        
        if use_llm and self.model_path.exists():
            self._load_model()
        else:
            print("üìù LLM Validator —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ —ç–≤—Ä–∏—Å—Ç–∏–∫ (–±–µ–∑ LLM)")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ LLM –º–æ–¥–µ–ª–∏"""
        try:
            from transformers import AutoModelForCausalLM, AutoTokenizer
            import torch
            
            print(f"–ó–∞–≥—Ä—É–∑–∫–∞ LLM –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ –∏–∑ {self.model_path}...")
            
            self.tokenizer = AutoTokenizer.from_pretrained(
                str(self.model_path),
                trust_remote_code=True
            )
            
            self.model = AutoModelForCausalLM.from_pretrained(
                str(self.model_path),
                device_map="cpu",
                torch_dtype=torch.float32,
                trust_remote_code=True,
                low_cpu_mem_usage=True
            )
            print("‚úì LLM –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å LLM –≤–∞–ª–∏–¥–∞—Ç–æ—Ä: {e}")
            print("–ë—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –ø—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏")
            self.model = None
            self.tokenizer = None
    
    def validate_and_calculate(
        self,
        original_query: str,
        found_items: List[Dict[str, Any]],
        max_iterations: int = 2
    ) -> Dict[str, Any]:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥: –≤–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å
        
        Args:
            original_query: –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            found_items: –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã [{"name": ..., "cost": ...}, ...]
            max_iterations: –º–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏, —Ä–∞—Å—á—ë—Ç–∞–º–∏ –∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
        """
        if self.model is None or self.tokenizer is None:
            # –†–µ–∂–∏–º —ç–≤—Ä–∏—Å—Ç–∏–∫
            return self._heuristic_validation(original_query, found_items)
        
        try:
            return self._llm_validation(original_query, found_items, max_iterations)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LLM –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            return self._heuristic_validation(original_query, found_items)
    
    def _llm_validation(
        self,
        original_query: str,
        found_items: List[Dict[str, Any]],
        max_iterations: int
    ) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ LLM
        """
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
        items_text = "\n".join([
            f"{i+1}. {item['name']} - {item.get('cost', 'N/A')} —Ä—É–±."
            for i, item in enumerate(found_items)
        ])
        
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –∏ –∫–æ–º–ø–ª–µ–∫—Ç—É—é—â–∏—Ö.

–ó–∞–¥–∞—á–∞: –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã. –û–ø—Ä–µ–¥–µ–ª–∏:
1. –ö–∞–∫–∏–µ —Ç–æ–≤–∞—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –∑–∞–ø—Ä–æ—Å—É
2. –°–∫–æ–ª—å–∫–æ –µ–¥–∏–Ω–∏—Ü –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ –Ω—É–∂–Ω–æ
3. –ß–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç (–µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω—É–∂–Ω–æ, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ)

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{original_query}

–ù–ê–ô–î–ï–ù–ù–´–ï –¢–û–í–ê–†–´:
{items_text}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
- –î–ª—è –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤ (–∫–æ—Ä–æ–± + –∫—Ä—ã—à–∫–∞ + –∫—Ä–µ–ø–µ–∂): –æ–±—ã—á–Ω–æ –Ω—É–∂–Ω—ã 1 –∫–æ—Ä–æ–±, 1 –∫—Ä—ã—à–∫–∞, 4 –≤–∏–Ω—Ç–∞, 4 –≥–∞–π–∫–∏
- –î–ª—è –º–æ–Ω—Ç–∞–∂–∞ –∫–æ—Ä–æ–±–æ–≤ 200x200: 4 –≤–∏–Ω—Ç–∞ –ú6 –∏ 4 –≥–∞–π–∫–∏ –ú6
- –î–ª—è –º–æ–Ω—Ç–∞–∂–∞ –ª–æ—Ç–∫–æ–≤: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –¥–ª–∏–Ω—ã (–æ–±—ã—á–Ω–æ –∫–∞–∂–¥—ã–µ 50—Å–º - 1 –∫—Ä–µ–ø–ª–µ–Ω–∏–µ)
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–∫–∞–∑–∞–ª –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —è–≤–Ω–æ - –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ
- –ï—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ - —Ä–∞—Å—Å—á–∏—Ç–∞–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê (JSON):
{{
  "analysis": "–∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞",
  "selected_items": [
    {{
      "item_index": 0,  // –∏–Ω–¥–µ–∫—Å —Ç–æ–≤–∞—Ä–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ (–Ω–∞—á–∏–Ω–∞—è —Å 0)
      "name": "–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞",
      "quantity": 2,  // —Å–∫–æ–ª—å–∫–æ –µ–¥–∏–Ω–∏—Ü –Ω—É–∂–Ω–æ
      "unit_price": 150,  // —Ü–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É
      "total_price": 300,  // –æ–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å (quantity * unit_price)
      "reason": "–ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω –∏ –ø–æ—á–µ–º—É —Ç–∞–∫–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"
    }}
  ],
  "missing_items": [
    // —Å–ø–∏—Å–æ–∫ —Ç–æ–≥–æ, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    {{
      "description": "—á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏",
      "reason": "–ø–æ—á–µ–º—É —ç—Ç–æ –Ω—É–∂–Ω–æ"
    }}
  ],
  "total_cost": 1500,  // –æ–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å –≤—Å–µ—Ö –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
  "confidence": 0.9  // —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ (0.0-1.0)
}}

JSON:"""

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        messages = [
            {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –ø–æ–¥–±–æ—Ä—É —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤."},
            {"role": "user", "content": prompt}
        ]
        
        text = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )
        
        model_inputs = self.tokenizer([text], return_tensors="pt").to(self.model.device)
        
        generated_ids = self.model.generate(
            **model_inputs,
            max_new_tokens=1024,
            temperature=0.3,
            do_sample=True,
            top_p=0.9
        )
        
        generated_ids = [
            output_ids[len(input_ids):] 
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        # –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
        result = self._parse_llm_validation_response(response, found_items)
        
        if result:
            print(f"‚úì LLM –≤–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(result['selected_items'])} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
            if result.get('missing_items'):
                print(f"‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç: {len(result['missing_items'])} –ø–æ–∑–∏—Ü–∏–π")
            return result
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç LLM, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫–∏")
            return self._heuristic_validation(original_query, found_items)
    
    def _parse_llm_validation_response(
        self, 
        response: str, 
        found_items: List[Dict]
    ) -> Optional[Dict]:
        """
        –ü–∞—Ä—Å–∏—Ç JSON –æ—Ç–≤–µ—Ç –æ—Ç LLM
        """
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(0))
                
                # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                if 'selected_items' in data and 'total_cost' in data:
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–∞—Ö
                    for item in data['selected_items']:
                        idx = item.get('item_index', -1)
                        if 0 <= idx < len(found_items):
                            item['full_data'] = found_items[idx]
                    
                    return data
            
            return None
            
        except json.JSONDecodeError as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            return None
    
    def _heuristic_validation(
        self,
        original_query: str,
        found_items: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –±–µ–∑ LLM
        
        –ü—Ä–∞–≤–∏–ª–∞:
        - –ë–µ—Ä–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
        - –î–ª—è –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤: 1 –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–æ–≤–∞—Ä, 1 –∫—Ä—ã—à–∫–∞, 4 –≤–∏–Ω—Ç–∞, 4 –≥–∞–π–∫–∏
        - –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: 1 –µ–¥–∏–Ω–∏—Ü–∞ –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        """
        query_lower = original_query.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        is_assembly = any(kw in query_lower for kw in ['–∫–æ–º–ø–ª–µ–∫—Ç', '–Ω–∞–±–æ—Ä', '–º–æ–Ω—Ç–∞–∂', '—É—Å—Ç–∞–Ω–æ–≤–∫–∞'])
        
        selected_items = []
        total_cost = 0
        
        for idx, item in enumerate(found_items):
            name_lower = item['name'].lower()
            unit_price = item.get('cost', 0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
            if is_assembly:
                # –î–ª—è –∫–æ–º–ø–ª–µ–∫—Ç–æ–≤
                if any(word in name_lower for word in ['–≤–∏–Ω—Ç', '–±–æ–ª—Ç']):
                    quantity = 4  # 4 –≤–∏–Ω—Ç–∞ –¥–ª—è –º–æ–Ω—Ç–∞–∂–∞
                elif '–≥–∞–π–∫' in name_lower:
                    quantity = 4  # 4 –≥–∞–π–∫–∏
                elif any(word in name_lower for word in ['—à–∞–π–±']):
                    quantity = 4  # 4 —à–∞–π–±—ã
                elif any(word in name_lower for word in ['–∫–æ—Ä–æ–±', '–ª–æ—Ç–æ–∫', '–∫–æ—Ä–ø—É—Å', '–∫—Ä—ã—à–∫–∞']):
                    quantity = 1  # 1 –æ—Å–Ω–æ–≤–Ω–æ–π —ç–ª–µ–º–µ–Ω—Ç
                else:
                    quantity = 1
            else:
                # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ - –ø–æ 1 –µ–¥–∏–Ω–∏—Ü–µ
                quantity = 1
            
            total_price = unit_price * quantity
            total_cost += total_price
            
            selected_items.append({
                "item_index": idx,
                "name": item['name'],
                "quantity": quantity,
                "unit_price": unit_price,
                "total_price": total_price,
                "reason": "–≤—ã–±—Ä–∞–Ω–æ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏",
                "full_data": item
            })
        
        return {
            "analysis": f"–≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: {'–∫–æ–º–ø–ª–µ–∫—Ç' if is_assembly else '–ø—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å'}",
            "selected_items": selected_items,
            "missing_items": [],
            "total_cost": total_cost,
            "confidence": 0.7,  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —ç–≤—Ä–∏—Å—Ç–∏–∫
            "method": "heuristic"
        }
    
    def format_result(self, validation_result: Dict) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
        """
        lines = []
        lines.append("=" * 60)
        lines.append("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
        lines.append("=" * 60)
        
        if 'analysis' in validation_result:
            lines.append(f"\nüí° –ê–Ω–∞–ª–∏–∑: {validation_result['analysis']}")
        
        lines.append(f"\n‚úÖ –í–´–ë–†–ê–ù–ù–´–ï –¢–û–í–ê–†–´ ({len(validation_result['selected_items'])} –ø–æ–∑.):")
        lines.append("-" * 60)
        
        for i, item in enumerate(validation_result['selected_items'], 1):
            lines.append(f"\n{i}. {item['name']}")
            lines.append(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {item['quantity']} —à—Ç.")
            lines.append(f"   –¶–µ–Ω–∞ –∑–∞ –µ–¥.: {item['unit_price']:,} —Ä—É–±.")
            lines.append(f"   –ò—Ç–æ–≥–æ: {item['total_price']:,} —Ä—É–±.")
            if 'reason' in item:
                lines.append(f"   –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {item['reason']}")
        
        if validation_result.get('missing_items'):
            lines.append(f"\n‚ö†Ô∏è –ù–ï –•–í–ê–¢–ê–ï–¢ ({len(validation_result['missing_items'])} –ø–æ–∑.):")
            lines.append("-" * 60)
            for i, missing in enumerate(validation_result['missing_items'], 1):
                lines.append(f"\n{i}. {missing['description']}")
                if 'reason' in missing:
                    lines.append(f"   –ü—Ä–∏—á–∏–Ω–∞: {missing['reason']}")
        
        lines.append(f"\n{'=' * 60}")
        lines.append(f"üí∞ –û–ë–©–ê–Ø –°–¢–û–ò–ú–û–°–¢–¨: {validation_result['total_cost']:,} —Ä—É–±.")
        lines.append(f"üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {validation_result.get('confidence', 0):.0%}")
        lines.append("=" * 60)
        
        return "\n".join(lines)


class IterativeSearchValidator(LLMValidator):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    
    –ï—Å–ª–∏ LLM –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —á—Ç–æ —á–µ–≥–æ-—Ç–æ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç - –¥–µ–ª–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ –ø–æ–∏—Å–∫—É
    """
    
    def __init__(self, *args, search_engine=None, **kwargs):
        """
        Args:
            search_engine: —ç–∫–∑–µ–º–ø–ª—è—Ä VectorSearchEngine –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        """
        super().__init__(*args, **kwargs)
        self.search_engine = search_engine
    
    def validate_with_iterative_search(
        self,
        original_query: str,
        initial_items: List[Dict[str, Any]],
        max_iterations: int = 2,
        items_per_search: int = 3
    ) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        
        Args:
            original_query: –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            initial_items: –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
            max_iterations: –º–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            items_per_search: —Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤ –∏—Å–∫–∞—Ç—å –≤ –∫–∞–∂–¥–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É—á—ë—Ç–æ–º –≤—Å–µ—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π
        """
        if not self.search_engine:
            print("‚ö†Ô∏è Search engine –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Ç–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω")
            return self.validate_and_calculate(original_query, initial_items)
        
        all_found_items = initial_items.copy()
        iteration = 0
        
        print(f"\nüîç –ò–¢–ï–†–ê–¢–ò–í–ù–´–ô –ü–û–ò–°–ö (–º–∞–∫—Å. {max_iterations} –∏—Ç–µ—Ä–∞—Ü–∏–π)")
        print("=" * 60)
        
        while iteration < max_iterations:
            print(f"\nüìç –ò—Ç–µ—Ä–∞—Ü–∏—è {iteration + 1}/{max_iterations}")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result = self.validate_and_calculate(original_query, all_found_items)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–µ–Ω –ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
            missing = result.get('missing_items', [])
            
            if not missing:
                print("‚úì –í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ç–æ–≤–∞—Ä—ã –Ω–∞–π–¥–µ–Ω—ã!")
                break
            
            print(f"‚ö†Ô∏è –ù–µ —Ö–≤–∞—Ç–∞–µ—Ç: {len(missing)} –ø–æ–∑–∏—Ü–∏–π")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–µ–≥–æ —Ç–æ–≤–∞—Ä–∞
            new_items_found = False
            for missing_item in missing:
                search_query = missing_item['description']
                print(f"   üîé –ò—â–µ–º: {search_query}")
                
                # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ search engine
                search_results = self.search_engine.search(
                    search_query, 
                    top_k=items_per_search
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Ç–æ–≤–∞—Ä—ã (–µ—Å–ª–∏ –∏—Ö –µ—â–µ –Ω–µ—Ç)
                for product, score in search_results:
                    product_dict = {
                        'id': product.id,
                        'name': product.name,
                        'cost': product.cost,
                        'similarity': score
                    }
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                    if not any(item['id'] == product.id for item in all_found_items):
                        all_found_items.append(product_dict)
                        new_items_found = True
                        print(f"      ‚úì –î–æ–±–∞–≤–ª–µ–Ω: {product.name} ({score:.2f})")
            
            if not new_items_found:
                print("‚ö†Ô∏è –ù–æ–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–æ–∏—Å–∫")
                break
            
            iteration += 1
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
        print(f"\n‚úÖ –§–ò–ù–ê–õ–¨–ù–ê–Ø –í–ê–õ–ò–î–ê–¶–ò–Ø")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_found_items)}")
        final_result = self.validate_and_calculate(original_query, all_found_items)
        final_result['iterations'] = iteration + 1
        final_result['total_items_found'] = len(all_found_items)
        
        return final_result


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö
    test_query = "–ö–æ–º–ø–ª–µ–∫—Ç –¥–ª—è –º–æ–Ω—Ç–∞–∂–∞ –∫–æ—Ä–æ–±–∞ 200x200: –∫–æ—Ä–æ–±, –∫—Ä—ã—à–∫–∞, –≤–∏–Ω—Ç—ã –∏ –≥–∞–π–∫–∏"
    
    test_items = [
        {"id": 1, "name": "–ö–æ—Ä–æ–± IP65 200x200", "cost": 1500},
        {"id": 2, "name": "–ö—Ä—ã—à–∫–∞ –≥–ª—É—Ö–∞—è 200", "cost": 300},
        {"id": 3, "name": "–í–∏–Ω—Ç –ú6√ó20", "cost": 5},
        {"id": 4, "name": "–ì–∞–π–∫–∞ –ú6", "cost": 2},
    ]
    
    # –¢–µ—Å—Ç —Å —ç–≤—Ä–∏—Å—Ç–∏–∫–∞–º–∏
    validator = LLMValidator(use_llm=False)
    result = validator.validate_and_calculate(test_query, test_items)
    
    print(validator.format_result(result))
